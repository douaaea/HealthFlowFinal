# %%
# CELL 1: Imports
import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report
import time
import os
import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# %%
# CELL 2: Configuration
CSV_PATH = r"dataset_with_nlp.csv"  # Fixed filename - auto-generated by extract_biobert_features.py
MODEL_FILENAME = "xgboost_readmission_model.ubj"
OPTIONAL_JSON_EXPORT = os.getenv("EXPORT_JSON_MODEL", "false").lower() == "true"
LEGACY_JSON_PATH = "xgboost_readmission_model.json"
TARGET_COL = 'label_readmission'
NULL_THRESHOLD = 0.80  # Drop columns with >80% null

print(f"ğŸ“‹ Configuration: {TARGET_COL} | Null threshold: {NULL_THRESHOLD*100}%")


# %%
# CELL 3: Load Raw Data
print(f"ğŸ“‚ Chargement de {CSV_PATH} ...")
start_time = time.time()

if not os.path.exists(CSV_PATH):
    raise FileNotFoundError(f"âŒ Fichier introuvable : {CSV_PATH}")

df_raw = pd.read_csv(CSV_PATH)
print(f"âœ… Dataset brut chargÃ©: {df_raw.shape[0]} lignes Ã— {df_raw.shape[1]} colonnes")
print(f"â±ï¸ Temps: {time.time() - start_time:.2f}s")


# %%
# CELL 4: Exploratory Data Analysis - Overview
print("ğŸ” === ANALYSE EXPLORATOIRE DES DONNÃ‰ES ===\n")

print(f"ğŸ“Š Shape: {df_raw.shape}")
print(f"\nğŸ“‹ Colonnes ({len(df_raw.columns)}):")
print(df_raw.columns.tolist())

print(f"\nğŸ¯ Target Distribution:")
print(df_raw[TARGET_COL].value_counts())
print(f"\nBalance: {df_raw[TARGET_COL].value_counts(normalize=True).round(3)}")

print("\nğŸ‘ï¸ AperÃ§u des premiÃ¨res lignes:")
df_raw.head()


# %%
# CELL 5: EDA - Missing Values Analysis
print("ğŸ•³ï¸ === ANALYSE DES VALEURS MANQUANTES ===\n")

# Calculate missing percentages
missing_stats = pd.DataFrame({
    'Column': df_raw.columns,
    'Missing_Count': df_raw.isnull().sum(),
    'Missing_Percent': (df_raw.isnull().sum() / len(df_raw) * 100).round(2)
}).sort_values('Missing_Percent', ascending=False)

print(missing_stats[missing_stats['Missing_Count'] > 0])

# Visualize missing data
plt.figure(figsize=(12, 6))
missing_cols = missing_stats[missing_stats['Missing_Count'] > 0].head(15)
sns.barplot(data=missing_cols, x='Missing_Percent', y='Column', palette='viridis')
plt.xlabel('Pourcentage de valeurs manquantes (%)')
plt.title('Top 15 colonnes avec valeurs manquantes')
plt.tight_layout()
plt.show()

print(f"\nâš ï¸ Colonnes avec >{NULL_THRESHOLD*100}% de null:")
high_null_cols = missing_stats[missing_stats['Missing_Percent'] > NULL_THRESHOLD*100]['Column'].tolist()
print(high_null_cols if high_null_cols else "Aucune")


# %%
# CELL 6: EDA - Data Types & Unique Values
print("ğŸ”¢ === TYPES DE DONNÃ‰ES ===\n")
print(df_raw.dtypes.value_counts())

print("\nğŸ“Š Valeurs uniques par colonne:")
unique_counts = df_raw.nunique().sort_values()
print(unique_counts)

# Identify binary columns
binary_cols = [col for col in df_raw.columns if df_raw[col].nunique() <= 2 and col not in ['encounter_id', 'patient_id', 'start_date']]
print(f"\nâœ… Colonnes binaires dÃ©tectÃ©es ({len(binary_cols)}): DÃ©jÃ  encodÃ©es")


# %%
# CELL 7: EDA - Statistical Summary
print("ğŸ“ˆ === STATISTIQUES DESCRIPTIVES ===\n")

# Numeric columns only
numeric_cols = df_raw.select_dtypes(include=[np.number]).columns.tolist()
print(df_raw[numeric_cols].describe().T)

# Check for outliers in vital signs
vital_cols = [col for col in df_raw.columns if col.startswith('vit_')]
print(f"\nğŸ©º Colonnes de signes vitaux: {vital_cols}")


# %%
# CELL 7.5: Correlation Analysis
print("\nğŸ”— === ANALYSE DE CORRÃ‰LATION ===\n")

# Calculate correlation matrix for numeric features
numeric_df = df_raw.select_dtypes(include=[np.number])
correlation_matrix = numeric_df.corr()

# Plot correlation heatmap
plt.figure(figsize=(20, 16))
sns.heatmap(
    correlation_matrix, 
    annot=False,  # Don't show values (too many features)
    cmap='coolwarm', 
    center=0,
    vmin=-1, 
    vmax=1,
    square=True,
    linewidths=0.5,
    cbar_kws={"shrink": 0.8}
)
plt.title('Correlation Matrix - All Features', fontsize=16, fontweight='bold')
plt.tight_layout()
plt.show()

# Show top correlations with target
if TARGET_COL in correlation_matrix.columns:
    target_corr = correlation_matrix[TARGET_COL].sort_values(ascending=False)
    print(f"\nğŸ“Š Top 15 correlations with {TARGET_COL}:")
    print(target_corr.head(15))
    print(f"\nğŸ“Š Bottom 15 correlations with {TARGET_COL}:")
    print(target_corr.tail(15))
    
    # Plot top correlations
    plt.figure(figsize=(10, 8))
    top_features = pd.concat([target_corr.head(15), target_corr.tail(15)]).drop(TARGET_COL)
    top_features.sort_values().plot(kind='barh', color=['red' if x < 0 else 'green' for x in top_features])
    plt.title(f'Top Features Correlated with {TARGET_COL}', fontsize=14, fontweight='bold')
    plt.xlabel('Correlation Coefficient')
    plt.tight_layout()
    plt.show()


# %%
# CELL 8: Data Cleaning - Drop High-Null Columns
print("ğŸ§¹ === NETTOYAGE DES DONNÃ‰ES ===\n")

df = df_raw.copy()

# Drop columns with >90% null
null_percentages = (df.isnull().sum() / len(df) * 100)
cols_to_drop_null = null_percentages[null_percentages > NULL_THRESHOLD * 100].index.tolist()

if cols_to_drop_null:
    print(f"âŒ Suppression de {len(cols_to_drop_null)} colonnes (>{NULL_THRESHOLD*100}% null):")
    print(cols_to_drop_null)
    df = df.drop(columns=cols_to_drop_null)
else:
    print(f"âœ… Aucune colonne avec >{NULL_THRESHOLD*100}% de valeurs manquantes")

print(f"\nğŸ“Š Shape aprÃ¨s suppression: {df.shape}")


# %%
# CELL 9: Data Cleaning - Drop Identifier Columns
print("ğŸ—‘ï¸ Suppression des colonnes identifiantes...")

cols_to_drop_ids = ['encounter_id', 'patient_id', 'start_date']
cols_to_drop_ids = [c for c in cols_to_drop_ids if c in df.columns]

if cols_to_drop_ids:
    print(f"âŒ Suppression: {cols_to_drop_ids}")
    df = df.drop(columns=cols_to_drop_ids)

print(f"âœ… Shape finale: {df.shape}")


# %%
# CELL 10: Encoding Check & Feature Engineering
print("ğŸ”§ === VÃ‰RIFICATION DE L'ENCODAGE ===\n")

# Check if categorical columns exist (non-numeric, non-binary)
categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
categorical_cols = [col for col in categorical_cols if col != TARGET_COL]

if categorical_cols:
    print(f"âš ï¸ Colonnes catÃ©gorielles dÃ©tectÃ©es: {categorical_cols}")
    print("Encodage requis (One-Hot ou Label Encoding)")
    
    # Example: One-hot encoding
    # df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)
    # print(f"âœ… Encodage appliquÃ©. Nouvelles colonnes: {df.shape[1]}")
else:
    print("âœ… Toutes les colonnes sont dÃ©jÃ  numÃ©riques/binaires")

print(f"\nğŸ“‹ Colonnes finales ({len(df.columns)}):")
print(df.columns.tolist())


# %%
# CELL 11: Missing Value Imputation Strategy
print("ğŸ”§ === TRAITEMENT DES VALEURS MANQUANTES RESTANTES ===\n")

remaining_nulls = df.isnull().sum()
cols_with_nulls = remaining_nulls[remaining_nulls > 0]

if len(cols_with_nulls) > 0:
    print(f"âš ï¸ Colonnes avec nulls restants:")
    print(cols_with_nulls)
    
    # Strategy for vital signs: median imputation or leave as NaN (XGBoost handles it)
    print("\nğŸ©º StratÃ©gie pour vit_*: Laisser NaN (XGBoost supporte nativement)")
    print("   Alternative: df[vital_cols] = df[vital_cols].fillna(df[vital_cols].median())")
    
    # Uncomment to impute:
    # vital_cols = [col for col in df.columns if col.startswith('vit_')]
    # df[vital_cols] = df[vital_cols].fillna(df[vital_cols].median())
    # print("âœ… Imputation mÃ©diane appliquÃ©e aux signes vitaux")
else:
    print("âœ… Aucune valeur manquante restante")

print(f"\nğŸ“Š Dataset final prÃªt: {df.shape}")
df.head()


# %%
# CELL 11.5: Feature Selection - Remove Constants
print("ğŸ”§ === SÃ‰LECTION DES FEATURES ===\n")

# Remove constant columns (0 variance)
constant_cols = [col for col in df.columns 
                if df[col].nunique() <= 1 and col != TARGET_COL]
if constant_cols:
    print(f"âŒ Constantes supprimÃ©es: {constant_cols}")
    df = df.drop(columns=constant_cols)

# Remove near-constant (<1% positive)
low_var_cols = [col for col in df.columns 
               if (df[col].sum() / len(df) < 0.01) and col != TARGET_COL]
print(f"â„¹ï¸ Faible variance (<1%): {low_var_cols}")

print(f"âœ… Features finales: {df.shape[1]-1}")


# %%
# CELL 12: Train/Val/Test Split (60/20/20)
print("âœ‚ï¸ === SÃ‰PARATION TRAIN/VAL/TEST ===\n")

if TARGET_COL not in df.columns:
    raise ValueError(f"âŒ Erreur : La colonne '{TARGET_COL}' est absente !")

X = df.drop(columns=[TARGET_COL])
y = df[TARGET_COL]

print(f"ğŸ“Š Features: {X.shape[1]}, Samples: {X.shape[0]}")

# First split: 80% train+val, 20% test
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Second split: 75% of temp (60% total) train, 25% of temp (20% total) val
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp
)

print(f"âœ… Train: {X_train.shape[0]} | Val: {X_val.shape[0]} | Test: {X_test.shape[0]}")
print(f"ğŸ“Š Train distribution:\n{y_train.value_counts(normalize=True).round(3)}")
print(f"ğŸ“Š Val distribution:\n{y_val.value_counts(normalize=True).round(3)}")


# %%
# CELL 13: Device Detection & Model Configuration
def detect_device() -> str:
    if torch.cuda.is_available():
        print("ğŸŸ¢ CUDA dÃ©tectÃ© : utilisation du GPU NVIDIA.")
        return "cuda"
    print("â„¹ï¸ CPU uniquement (pas de support CUDA/MPS pour XGBoost).")
    return "cpu"

device = detect_device()
print(f"ğŸš€ Initialisation de XGBoost sur {device.upper()}...")

model = xgb.XGBClassifier(
    device=device,
    tree_method="hist",
    n_estimators=500,
    learning_rate=0.03,
    max_depth=4,              # Reduced from 6 to prevent overfitting
    subsample=0.7,            # Reduced from 0.8 for more regularization
    colsample_bytree=0.7,     # Reduced from 0.8 for more regularization
    objective='binary:logistic',
    eval_metric='auc',
    early_stopping_rounds=50,
    missing=float('nan'),
    reg_alpha=1.0,            # L1 regularization
    reg_lambda=5.0,           # L2 regularization (increased for better generalization)
    gamma=0.5,                # Minimum loss reduction (higher = more conservative)
    min_child_weight=5        # Minimum sum of instance weight (prevents small leaves)
)

print("âœ… ModÃ¨le configurÃ©!")


# %%
# CELL 13: Training WITH Train/Val/Test Tracking
print("ğŸ”¥ === ENTRAÃNEMENT Train/Val/Test tracking ===\n")
start_train = time.time()

model.fit(
    X_train, y_train,
    eval_set=[(X_train, y_train), (X_val, y_val)],  # Use validation set for early stopping
    verbose=100
)

print(f"âœ… TerminÃ© en {time.time() - start_time:.2f}s")
print(f"ğŸ† Best iteration: {model.best_iteration}")


# %%
# CELL 14.5: Extract Training History (StackOverflow #1 method)
import matplotlib.pyplot as plt
import numpy as np

# Get evaluation results directly from XGBoost
results = model.evals_result()
epochs = len(results['validation_0']['auc'])
x_axis = range(0, epochs)

print(f"ğŸ“Š {epochs} iterations tracked")
print(f"ğŸ† Best iteration: {model.best_iteration}")
print(f"ğŸ“ˆ Peak AUC: {max(results['validation_0']['auc']):.4f}")


# %%
# CELL 15: Train vs Test Dashboard (FINAL FIXED VERSION)
results = model.evals_result()

# Auto-detect keys
train_key = 'validation_0'  # Train set
test_key = 'validation_1'   # Test set

epochs = len(results[test_key]['auc'])
x_axis = range(0, epochs)

fig, axes = plt.subplots(2, 2, figsize=(16, 12))
fig.suptitle('XGBoost: Train vs Test Curves', fontsize=16, fontweight='bold')

# 1. AUC Curves
axes[0,0].plot(x_axis, results[train_key]['auc'], 'g-', linewidth=3, label='Train AUC')
axes[0,0].plot(x_axis, results[test_key]['auc'], 'b-', linewidth=3, label='Test AUC')  
axes[0,0].axvline(model.best_iteration, color='red', linestyle='--', linewidth=2)
axes[0,0].set_title('AUC: Train vs Test')
axes[0,0].legend(); axes[0,0].grid(True, alpha=0.3)

# 2. Loss Curves
train_loss = 1 - np.array(results[train_key]['auc'])
test_loss = 1 - np.array(results[test_key]['auc'])
axes[0,1].plot(x_axis, train_loss, 'g-', linewidth=3, label='Train Loss')
axes[0,1].plot(x_axis, test_loss, 'r-', linewidth=3, label='Test Loss')
axes[0,1].axvline(model.best_iteration, color='red', linestyle='--')
axes[0,1].set_title('Loss: Train vs Test')
axes[0,1].legend(); axes[0,1].grid(True, alpha=0.3)

# 3. Overfitting Gap
gap = np.array(results[train_key]['auc']) - np.array(results[test_key]['auc'])
axes[1,0].plot(x_axis, gap, 'purple', linewidth=3)
axes[1,0].axhline(0, color='black', linestyle='-', alpha=0.5)
axes[1,0].axvline(model.best_iteration, color='red', linestyle='--')
axes[1,0].set_title('Overfitting Gap (Train-Test AUC)')
axes[1,0].set_ylabel('AUC Gap'); axes[1,0].grid(True, alpha=0.3)

# 4. Feature Importance
feature_imp = pd.DataFrame({'feature': X.columns, 'importance': model.feature_importances_}).sort_values('importance', ascending=False).head(10)
sns.barplot(data=feature_imp, y='feature', x='importance', ax=axes[1,1])
axes[1,1].set_title('Top 10 Features')

plt.tight_layout()
plt.show()

print(f"Train AUC: {results[train_key]['auc'][-1]:.4f}")
print(f"Test AUC:  {results[test_key]['auc'][-1]:.4f}")
print(f"Max Gap:   {max(gap):.4f}")


# %%
# CELL 15: Generate Predictions
print("ğŸ”® === GÃ‰NÃ‰RATION DES PRÃ‰DICTIONS ===\n")

# Binary predictions (0 or 1)
y_pred = model.predict(X_test)

# Probability predictions for ROC curve
y_prob = model.predict_proba(X_test)[:, 1]

print(f"âœ… Predictions generated: {len(y_pred)} samples")
print(f"ğŸ“Š Prediction distribution:\n{pd.Series(y_pred).value_counts()}")

# Calculate metrics
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report

accuracy = accuracy_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_prob)

print(f"\nğŸ¯ Test Accuracy: {accuracy:.4f}")
print(f"ğŸ“ˆ Test ROC-AUC: {roc_auc:.4f}")
print(f"\nğŸ“‹ Classification Report:")
print(classification_report(y_test, y_pred, target_names=['No Readmission', 'Readmission']))


# %%
# CELL 16: Save Model
booster = model.get_booster()
booster.save_model(MODEL_FILENAME)
print(f"ğŸ’¾ ModÃ¨le sauvegardÃ©: {MODEL_FILENAME}")

if OPTIONAL_JSON_EXPORT:
    booster.save_model(LEGACY_JSON_PATH)
    print(f"ğŸ“ JSON export: {LEGACY_JSON_PATH}")

print("ğŸ‰ Pipeline complet terminÃ©!")



